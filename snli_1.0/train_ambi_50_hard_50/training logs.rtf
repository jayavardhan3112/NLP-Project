{\rtf1\ansi\ansicpg1252\cocoartf2636
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red25\green25\blue25;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c12941\c12941\c12941;\cssrgb\c100000\c100000\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
Training arguments Namespace(adam_epsilon=1e-08, distributed_backend=None, early_stop_callback=False, fp_16=False, max_grad_norm=1.0, n_gpu=-1, num_workers=8, opt_level='O1', warmup_steps=0, weight_decay=0.0)\
--------------------\
Model arguments Namespace(hidden_dropout_prob=0.15, max_input_seq_length=128, model_name_or_path='bert-base-uncased', num_labels=4)\
--------------------\
Other arguments Namespace(DEV_FILE='/content/dev.csv', TRAIN_FILE='/content/train_ambi_50_hard_50.csv', do_fast_dev_run=False, eval_batch_size=16, gradient_accumulation_steps=1, learning_rate=5e-05, limit_train_batches=-1, limit_val_batches=-1, max_train_samples=-1, num_train_epochs=5, output_dir='./', predictions_file='predictions.csv', save_last=False, save_top_k=-1, seed=42, train_batch_size=16, write_dev_predictions=True)\
--------------------\
Global seed set to 42\
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\
GPU available: True, used: True\
TPU available: False, using: 0 TPU cores\
IPU available: False, using: 0 IPUs\
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\
\
  | Name  | Type                          | Params\
--------------------------------------------------------\
0 | model | BertForSequenceClassification | 109 M \
--------------------------------------------------------\
109 M     Trainable params\
0         Non-trainable params\
109 M     Total params\
437.941   Total estimated model params size (MB)\
/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:623: UserWarning: Checkpoint directory /content exists and is not empty.\
  rank_zero_warn(f"Checkpoint directory \{dirpath\} exists and is not empty.")\
Validation sanity check: 0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\
  cpuset_checked))\
Validation sanity check:   0% 0/2 [00:00<?, ?it/s]--------------------\
Validation avg_loss:  tensor(1.7792, device='cuda:0')\
Validation avg_acc:  tensor(0., device='cuda:0')\
Writing predictions for /content/dev.csv to ./epoch_0_predictions.csv\
--------------------\
Global seed set to 42\
/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:408: UserWarning: The number of training samples (31) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\
  f"The number of training samples (\{self.num_training_batches\}) is smaller than the logging interval"\
Epoch 0:   6% 40/656 [00:21<05:26,  1.89it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Validating: 0it [00:00, ?it/s]\
Validating:   0% 0/625 [00:00<?, ?it/s]\
Epoch 0:   9% 60/656 [00:26<04:19,  2.29it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  12% 80/656 [00:30<03:40,  2.61it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  15% 100/656 [00:35<03:15,  2.85it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  18% 120/656 [00:39<02:56,  3.03it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  21% 140/656 [00:44<02:42,  3.17it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  24% 160/656 [00:48<02:30,  3.29it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  27% 180/656 [00:53<02:20,  3.39it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  30% 200/656 [00:57<02:11,  3.47it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  34% 220/656 [01:02<02:03,  3.54it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  37% 240/656 [01:06<01:55,  3.60it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  40% 260/656 [01:11<01:48,  3.65it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  43% 280/656 [01:15<01:41,  3.69it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  46% 300/656 [01:20<01:35,  3.73it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  49% 320/656 [01:25<01:29,  3.76it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  52% 340/656 [01:29<01:23,  3.80it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  55% 360/656 [01:34<01:17,  3.82it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  58% 380/656 [01:38<01:11,  3.85it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  61% 400/656 [01:43<01:06,  3.87it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  64% 420/656 [01:47<01:00,  3.89it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  67% 440/656 [01:52<00:55,  3.91it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  70% 460/656 [01:57<00:49,  3.93it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  73% 480/656 [02:01<00:44,  3.94it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  76% 500/656 [02:06<00:39,  3.96it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  79% 520/656 [02:10<00:34,  3.97it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  82% 540/656 [02:15<00:29,  3.98it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  85% 560/656 [02:20<00:24,  3.99it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  88% 580/656 [02:24<00:18,  4.01it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  91% 600/656 [02:29<00:13,  4.02it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  95% 620/656 [02:34<00:08,  4.03it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Epoch 0:  98% 640/656 [02:38<00:03,  4.04it/s, loss=1.16, v_num=3, train_loss_step=1.020, train_acc_step=0.500]\
Validating:  99% 620/625 [02:22<00:01,  4.35it/s]\
Validating: 100% 625/625 [02:23<00:00,  4.28it/s]--------------------\
Validation avg_loss:  tensor(1.2536, device='cuda:0')\
Validation avg_acc:  tensor(0.3235, device='cuda:0')\
Writing predictions for /content/dev.csv to ./epoch_0_predictions.csv\
--------------------\
Epoch 0: 100% 656/656 [02:44<00:00,  3.98it/s, loss=1.08, v_num=3, train_loss_step=1.030, train_acc_step=0.500]\
                                                 --------------------\
Train avg_loss:  tensor(1.1305, device='cuda:0')\
Train avg_acc:  tensor(0.5040, device='cuda:0')\
--------------------\
tcmalloc: large alloc 1092804608 bytes == 0x558cdbfe6000 @  0x7fa1b2e70615 0x558bf45734cc 0x558bf465347a 0x558bf4579f0c 0x7fa1ae0c29e4 0x7fa1ae0cab14 0x7fa1ae09fa60 0x7fa10587df55 0x7fa10587988e 0x7fa105881235 0x7fa1ae09ffae 0x7fa1ad816aa8 0x558bf4577098 0x558bf45ea4d9 0x558bf45e4ced 0x558bf4577bda 0x558bf45e5915 0x558bf45e49ee 0x558bf4577bda 0x558bf45e9d00 0x558bf4577afa 0x558bf45e5915 0x558bf45e49ee 0x558bf4577bda 0x558bf45e5c0d 0x558bf4577afa 0x558bf45e5c0d 0x558bf45e49ee 0x558bf4577bda 0x558bf45e5c0d 0x558bf45e49ee\
tcmalloc: large alloc 1366007808 bytes == 0x558c7e32a000 @  0x7fa1b2e70615 0x558bf45734cc 0x558bf465347a 0x558bf4579f0c 0x7fa1ae0c29e4 0x7fa1ae0cab14 0x7fa1ae09fa60 0x7fa10587df55 0x7fa10587988e 0x7fa105881235 0x7fa1ae09ffae 0x7fa1ad816aa8 0x558bf4577098 0x558bf45ea4d9 0x558bf45e4ced 0x558bf4577bda 0x558bf45e5915 0x558bf45e49ee 0x558bf4577bda 0x558bf45e9d00 0x558bf4577afa 0x558bf45e5915 0x558bf45e49ee 0x558bf4577bda 0x558bf45e5c0d 0x558bf4577afa 0x558bf45e5c0d 0x558bf45e49ee 0x558bf4577bda 0x558bf45e5c0d 0x558bf45e49ee\
tcmalloc: large alloc 1707515904 bytes == 0x558d272fa000 @  0x7fa1b2e70615 0x558bf45734cc 0x558bf465347a 0x558bf4579f0c 0x7fa1ae0c29e4 0x7fa1ae0cab14 0x7fa1ae09fa60 0x7fa10587df55 0x7fa10587988e 0x7fa105881235 0x7fa1ae09ffae 0x7fa1ad816aa8 0x558bf4577098 0x558bf45ea4d9 0x558bf45e4ced 0x558bf4577bda 0x558bf45e5915 0x558bf45e49ee 0x558bf4577bda 0x558bf45e9d00 0x558bf4577afa 0x558bf45e5915 0x558bf45e49ee 0x558bf4577bda 0x558bf45e5c0d 0x558bf4577afa 0x558bf45e5c0d 0x558bf45e49ee 0x558bf4577bda 0x558bf45e5c0d 0x558bf45e49ee\
Epoch 1:   6% 40/656 [00:22<05:48,  1.77it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Validating: 0it [00:00, ?it/s]\
Validating:   0% 0/625 [00:00<?, ?it/s]\
Epoch 1:   9% 60/656 [00:28<04:39,  2.14it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  12% 80/656 [00:32<03:55,  2.44it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  15% 100/656 [00:37<03:27,  2.68it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  18% 120/656 [00:41<03:07,  2.86it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  21% 140/656 [00:46<02:51,  3.00it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  24% 160/656 [00:51<02:38,  3.12it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  27% 180/656 [00:55<02:27,  3.22it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  30% 200/656 [01:00<02:17,  3.31it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  34% 220/656 [01:05<02:09,  3.38it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  37% 240/656 [01:09<02:00,  3.44it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  40% 260/656 [01:14<01:53,  3.50it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  43% 280/656 [01:19<01:46,  3.54it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  46% 300/656 [01:23<01:39,  3.59it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  49% 320/656 [01:28<01:32,  3.63it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  52% 340/656 [01:32<01:26,  3.66it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  55% 360/656 [01:37<01:20,  3.69it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  58% 380/656 [01:42<01:14,  3.72it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  61% 400/656 [01:46<01:08,  3.75it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  64% 420/656 [01:51<01:02,  3.77it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  67% 440/656 [01:56<00:56,  3.79it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  70% 460/656 [02:00<00:51,  3.81it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  73% 480/656 [02:05<00:45,  3.83it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  76% 500/656 [02:09<00:40,  3.85it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  79% 520/656 [02:14<00:35,  3.87it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  82% 540/656 [02:19<00:29,  3.88it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  85% 560/656 [02:23<00:24,  3.90it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  88% 580/656 [02:28<00:19,  3.91it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  91% 600/656 [02:33<00:14,  3.92it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  95% 620/656 [02:37<00:09,  3.93it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Epoch 1:  98% 640/656 [02:42<00:04,  3.94it/s, loss=1.04, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
Validating:  99% 620/625 [02:24<00:01,  4.32it/s]\
Validating: 100% 625/625 [02:25<00:00,  4.19it/s]--------------------\
Validation avg_loss:  tensor(1.2909, device='cuda:0')\
Validation avg_acc:  tensor(0.3235, device='cuda:0')\
Writing predictions for /content/dev.csv to ./epoch_1_predictions.csv\
--------------------\
Epoch 1: 100% 656/656 [02:48<00:00,  3.89it/s, loss=1.05, v_num=3, train_loss_step=1.020, train_acc_step=0.562, train_loss_epoch=1.130, train_acc_epoch=0.504]\
                                                 --------------------\
Train avg_loss:  tensor(1.0394, device='cuda:0')\
Train avg_acc:  tensor(0.5403, device='cuda:0')\
--------------------\
tcmalloc: large alloc 1707515904 bytes == 0x558c7e32a000 @  0x7fa1b2e70615 0x558bf45734cc 0x558bf465347a 0x558bf4579f0c 0x7fa1ae0c29e4 0x7fa1ae0cab14 0x7fa1ae09fa60 0x7fa10587df55 0x7fa10587988e 0x7fa105881235 0x7fa1ae09ffae 0x7fa1ad816aa8 0x558bf4577098 0x558bf45ea4d9 0x558bf45e4ced 0x558bf4577bda 0x558bf45e5915 0x558bf45e49ee 0x558bf4577bda 0x558bf45e9d00 0x558bf4577afa 0x558bf45e5915 0x558bf45e49ee 0x558bf4577bda 0x558bf45e5c0d 0x558bf4577afa 0x558bf45e5c0d 0x558bf45e49ee 0x558bf4577bda 0x558bf45e5c0d 0x558bf45e49ee\
Epoch 2:   6% 40/656 [00:22<05:46,  1.78it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Validating: 0it [00:00, ?it/s]\
Validating:   0% 0/625 [00:00<?, ?it/s]\
Epoch 2:   9% 60/656 [00:27<04:36,  2.16it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  12% 80/656 [00:32<03:53,  2.47it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  15% 100/656 [00:37<03:26,  2.70it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  18% 120/656 [00:41<03:06,  2.88it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  21% 140/656 [00:46<02:50,  3.02it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  24% 160/656 [00:50<02:38,  3.14it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  27% 180/656 [00:55<02:27,  3.24it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  30% 200/656 [01:00<02:17,  3.32it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  34% 220/656 [01:04<02:08,  3.39it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  37% 240/656 [01:09<02:00,  3.45it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  40% 260/656 [01:14<01:52,  3.51it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  43% 280/656 [01:18<01:45,  3.55it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  46% 300/656 [01:23<01:38,  3.60it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  49% 320/656 [01:28<01:32,  3.64it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  52% 340/656 [01:32<01:26,  3.66it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  55% 360/656 [01:37<01:20,  3.69it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  58% 380/656 [01:42<01:14,  3.72it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  61% 400/656 [01:46<01:08,  3.75it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  64% 420/656 [01:51<01:02,  3.77it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  67% 440/656 [01:56<00:56,  3.79it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  70% 460/656 [02:00<00:51,  3.81it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  73% 480/656 [02:05<00:45,  3.83it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  76% 500/656 [02:09<00:40,  3.85it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  79% 520/656 [02:14<00:35,  3.87it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  82% 540/656 [02:19<00:29,  3.88it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  85% 560/656 [02:23<00:24,  3.89it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  88% 580/656 [02:28<00:19,  3.91it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  91% 600/656 [02:33<00:14,  3.92it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  95% 620/656 [02:37<00:09,  3.93it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Epoch 2:  98% 640/656 [02:42<00:04,  3.94it/s, loss=1.03, v_num=3, train_loss_step=1.110, train_acc_step=0.375, train_loss_epoch=1.040, train_acc_epoch=0.540]\
Validating:  99% 620/625 [02:24<00:01,  4.32it/s]\
Validating: 100% 625/625 [02:25<00:00,  4.20it/s]--------------------\
Validation avg_loss:  tensor(1.3045, device='cuda:0')\
Validation avg_acc:  tensor(0.3235, device='cuda:0')\
Writing predictions for /content/dev.csv to ./epoch_2_predictions.csv\
--------------------\
Epoch 2: 100% 656/656 [02:48<00:00,  3.89it/s, loss=0.986, v_num=3, train_loss_step=1.040, train_acc_step=0.562, train_loss_epoch=1.040, train_acc_epoch=0.540]\
                                                 --------------------\
Train avg_loss:  tensor(1.0127, device='cuda:0')\
Train avg_acc:  tensor(0.5363, device='cuda:0')\
--------------------\
Epoch 3:   6% 40/656 [00:22<05:44,  1.79it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Validating: 0it [00:00, ?it/s]\
Validating:   0% 0/625 [00:00<?, ?it/s]\
Epoch 3:   9% 60/656 [00:27<04:35,  2.16it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  12% 80/656 [00:32<03:53,  2.47it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  15% 100/656 [00:37<03:26,  2.70it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  18% 120/656 [00:41<03:06,  2.88it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  21% 140/656 [00:46<02:50,  3.02it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  24% 160/656 [00:50<02:38,  3.14it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  27% 180/656 [00:55<02:27,  3.24it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  30% 200/656 [01:00<02:17,  3.32it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  34% 220/656 [01:04<02:08,  3.39it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  37% 240/656 [01:09<02:00,  3.45it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  40% 260/656 [01:14<01:52,  3.51it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  43% 280/656 [01:18<01:45,  3.55it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  46% 300/656 [01:23<01:39,  3.60it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  49% 320/656 [01:28<01:32,  3.63it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  52% 340/656 [01:32<01:26,  3.67it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  55% 360/656 [01:37<01:20,  3.70it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  58% 380/656 [01:41<01:14,  3.73it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  61% 400/656 [01:46<01:08,  3.75it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  64% 420/656 [01:51<01:02,  3.78it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  67% 440/656 [01:55<00:56,  3.80it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  70% 460/656 [02:00<00:51,  3.82it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  73% 480/656 [02:05<00:45,  3.84it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  76% 500/656 [02:09<00:40,  3.85it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  79% 520/656 [02:14<00:35,  3.87it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  82% 540/656 [02:19<00:29,  3.88it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  85% 560/656 [02:23<00:24,  3.90it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  88% 580/656 [02:28<00:19,  3.91it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  91% 600/656 [02:32<00:14,  3.92it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  95% 620/656 [02:37<00:09,  3.94it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Epoch 3:  98% 640/656 [02:42<00:04,  3.95it/s, loss=0.983, v_num=3, train_loss_step=0.972, train_acc_step=0.562, train_loss_epoch=1.010, train_acc_epoch=0.536]\
Validating:  99% 620/625 [02:24<00:01,  4.32it/s]\
Validating: 100% 625/625 [02:25<00:00,  4.22it/s]--------------------\
Validation avg_loss:  tensor(1.3110, device='cuda:0')\
Validation avg_acc:  tensor(0.3205, device='cuda:0')\
Writing predictions for /content/dev.csv to ./epoch_3_predictions.csv\
--------------------\
Epoch 3: 100% 656/656 [02:48<00:00,  3.90it/s, loss=0.994, v_num=3, train_loss_step=0.956, train_acc_step=0.500, train_loss_epoch=1.010, train_acc_epoch=0.536]\
                                                 --------------------\
Train avg_loss:  tensor(0.9854, device='cuda:0')\
Train avg_acc:  tensor(0.5524, device='cuda:0')\
--------------------\
Epoch 4:   6% 40/656 [00:22<05:47,  1.77it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Validating: 0it [00:00, ?it/s]\
Validating:   0% 0/625 [00:00<?, ?it/s]\
Epoch 4:   9% 60/656 [00:27<04:37,  2.15it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  12% 80/656 [00:32<03:54,  2.45it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  15% 100/656 [00:37<03:27,  2.69it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  18% 120/656 [00:41<03:07,  2.87it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  21% 140/656 [00:46<02:51,  3.01it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  24% 160/656 [00:51<02:38,  3.13it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  27% 180/656 [00:55<02:27,  3.23it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  30% 200/656 [01:00<02:17,  3.31it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  34% 220/656 [01:05<02:08,  3.38it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  37% 240/656 [01:09<02:00,  3.44it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  40% 260/656 [01:14<01:53,  3.50it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  43% 280/656 [01:18<01:46,  3.55it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  46% 300/656 [01:23<01:39,  3.59it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  49% 320/656 [01:28<01:32,  3.63it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  52% 340/656 [01:32<01:26,  3.66it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  55% 360/656 [01:37<01:20,  3.69it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  58% 380/656 [01:42<01:14,  3.72it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  61% 400/656 [01:46<01:08,  3.75it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  64% 420/656 [01:51<01:02,  3.77it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  67% 440/656 [01:56<00:56,  3.79it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  70% 460/656 [02:00<00:51,  3.81it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  73% 480/656 [02:05<00:45,  3.83it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  76% 500/656 [02:09<00:40,  3.85it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  79% 520/656 [02:14<00:35,  3.87it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  82% 540/656 [02:19<00:29,  3.88it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  85% 560/656 [02:23<00:24,  3.89it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  88% 580/656 [02:28<00:19,  3.91it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  91% 600/656 [02:33<00:14,  3.92it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  95% 620/656 [02:37<00:09,  3.93it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Epoch 4:  98% 640/656 [02:42<00:04,  3.94it/s, loss=0.904, v_num=3, train_loss_step=1.010, train_acc_step=0.562, train_loss_epoch=0.985, train_acc_epoch=0.552]\
Validating:  99% 620/625 [02:24<00:01,  4.32it/s]\
Validating: 100% 625/625 [02:25<00:00,  4.20it/s]--------------------\
Validation avg_loss:  tensor(1.3128, device='cuda:0')\
Validation avg_acc:  tensor(0.3187, device='cuda:0')\
Writing predictions for /content/dev.csv to ./epoch_4_predictions.csv\
--------------------\
Epoch 4: 100% 656/656 [02:48<00:00,  3.89it/s, loss=0.955, v_num=3, train_loss_step=0.831, train_acc_step=0.688, train_loss_epoch=0.985, train_acc_epoch=0.552]\
                                                 --------------------\
Train avg_loss:  tensor(0.9291, device='cuda:0')\
Train avg_acc:  tensor(0.5968, device='cuda:0')\
--------------------\
Epoch 4: 100% 656/656 [02:56<00:00,  3.72it/s, loss=0.955, v_num=3, train_loss_step=0.831, train_acc_step=0.688, train_loss_epoch=0.985, train_acc_epoch=0.552]}